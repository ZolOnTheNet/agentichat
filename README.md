# agentichat

> ğŸ“– **Version franÃ§aise** ci-dessous. [English version below](#english-version) â¬‡ï¸

**Assistant IA autonome dans votre terminal** - Interagissez avec vos fichiers, le web et vos tÃ¢ches grÃ¢ce Ã  une IA agentique propulsÃ©e par Ollama ou Albert API.

## âœ¨ FonctionnalitÃ©s

- ğŸ¤– **IA Agentique**: Assistant autonome avec 18 outils intÃ©grÃ©s (14 base + 4 Albert)
- ğŸ“ **OpÃ©rations Fichiers**: Lire, Ã©crire, chercher, lister fichiers et rÃ©pertoires
- ğŸŒ **AccÃ¨s Web**: RÃ©cupÃ©rer des URLs et rechercher sur le web (DuckDuckGo)
- ğŸ“‹ **Gestion de TÃ¢ches**: Liste TODO intÃ©grÃ©e avec suivi de statut
- ğŸ”„ **Interface Interactive**: Stats temps rÃ©el, confirmations, sÃ©lecteur de modÃ¨le
- ğŸ”’ **SÃ©curisÃ©**: OpÃ©rations fichiers en sandbox avec confirmations utilisateur
- âš¡ **Rapide**: OptimisÃ© pour Ollama avec support du streaming
- ğŸ‡«ğŸ‡· **Albert API**: Support de l'API Albert (Etalab) avec outils spÃ©cialisÃ©s

## ğŸš€ DÃ©marrage Rapide

### PrÃ©requis

- Python 3.11+
- [Ollama](https://ollama.ai/) installÃ© et en cours d'exÃ©cution OU
- Un compte [Albert API](https://albert.api.etalab.gouv.fr) (service public franÃ§ais)

### Installation

```bash
# Installation depuis les sources
git clone <repository>
cd agentichat
python -m venv .venv
source .venv/bin/activate  # ou `.venv\Scripts\activate` sous Windows
pip install -e .
```

### Premier Lancement

```bash
agentichat
```

Au premier lancement, le programme va:
1. DÃ©tecter si votre modÃ¨le configurÃ© est invalide
2. Afficher un sÃ©lecteur de modÃ¨le interactif
3. Sauvegarder votre choix dans la configuration

## ğŸ› ï¸ Outils Disponibles

L'assistant IA a accÃ¨s Ã  18 outils organisÃ©s par catÃ©gorie:

### ğŸ“ Fichiers (6 outils)
- `read_file` - Lire le contenu d'un fichier
- `write_file` - CrÃ©er ou modifier des fichiers
- `list_files` - Lister le contenu d'un rÃ©pertoire
- `delete_file` - Supprimer des fichiers
- `search_text` - Chercher du texte avec regex
- `glob_search` - Trouver des fichiers par pattern (ex: `*.py`, `**/*.js`)

### ğŸ“‚ RÃ©pertoires (4 outils)
- `create_directory` - CrÃ©er des rÃ©pertoires
- `delete_directory` - Supprimer des rÃ©pertoires
- `move_file` - DÃ©placer/renommer fichiers ou rÃ©pertoires
- `copy_file` - Copier fichiers ou rÃ©pertoires

### ğŸŒ Web (2 outils)
- `web_fetch` - RÃ©cupÃ©rer le contenu d'URLs
- `web_search` - Rechercher sur le web (DuckDuckGo)

### ğŸ’» SystÃ¨me (1 outil)
- `shell_exec` - ExÃ©cuter des commandes shell

### ğŸ“‹ ProductivitÃ© (1 outil)
- `todo_write` - GÃ©rer des listes de tÃ¢ches avec suivi de statut

### âš¡ Albert API uniquement (4 outils supplÃ©mentaires)
- `albert_search` - Recherche sÃ©mantique dans collections de documents
- `albert_ocr` - Extraire du texte depuis images/PDFs
- `albert_transcription` - Convertir audio en texte
- `albert_embeddings` - CrÃ©er des embeddings texte pour similaritÃ©

## ğŸ’¬ Utilisation

### Mode Interactif

```bash
agentichat
```

Posez simplement des questions en langage naturel:
```
> Liste tous les fichiers Python dans ce rÃ©pertoire
> Lis le fichier config et explique ce qu'il fait
> Recherche sur le web "Ollama function calling"
> CrÃ©e une liste TODO pour ce projet
```

L'IA utilisera automatiquement les outils appropriÃ©s pour complÃ©ter vos requÃªtes.

### Commandes

#### Commandes GÃ©nÃ©rales
- `/help` - Afficher l'aide
- `/quit`, `/exit`, `/q` - Quitter
- `/clear` - RÃ©initialiser la conversation
- `/config` - Afficher la configuration
- `/config backend list` - Lister les backends disponibles
- `/config backend <nom>` - Changer de backend (ollama/albert)

#### Commandes Ollama
- `/ollama list` - Lister les modÃ¨les disponibles
- `/ollama run <modÃ¨le>` - Changer de modÃ¨le
- `/ollama show <modÃ¨le>` - Afficher les dÃ©tails d'un modÃ¨le
- `/ollama ps` - Afficher les modÃ¨les en cours d'exÃ©cution

#### Commandes Albert
- `/albert list` - Lister les modÃ¨les Albert disponibles
- `/albert run <modÃ¨le>` - Changer de modÃ¨le Albert
- `/albert show <modÃ¨le>` - Afficher les dÃ©tails d'un modÃ¨le
- `/albert usage` - Afficher les statistiques d'utilisation
- `/albert me` - Afficher les informations du compte

### Raccourcis Clavier

- `Enter` - Envoyer le message
- `Alt+Enter` ou `Ctrl+J` - Nouvelle ligne
- `â†‘` / `â†“` - Naviguer dans l'historique (sur premiÃ¨re/derniÃ¨re ligne)
- `Esc` - Effacer l'entrÃ©e actuelle
- `Ctrl+D` - Quitter

## âš™ï¸ Configuration

Fichiers de configuration (par ordre de prioritÃ©):
1. `.agentichat/config.yaml` (local au workspace)
2. `~/.agentichat/config.yaml` (global)

### Configuration de Base (Ollama)

```yaml
default_backend: ollama

backends:
  ollama:
    type: ollama
    url: http://localhost:11434
    model: qwen2.5-coder:7b
    temperature: 0.7
    max_tokens: 4096
    timeout: 300

sandbox:
  max_file_size: 1000000  # 1 MB
  blocked_paths:
    - "**/.env"
    - "**/*.key"

confirmations:
  text_operations: true
  shell_commands: true

max_iterations: 10
```

### Utiliser Albert API (Etalab)

Albert est une API de service public franÃ§ais avec fonctionnalitÃ©s avancÃ©es:

```yaml
default_backend: albert

backends:
  albert:
    type: albert
    url: https://albert.api.etalab.gouv.fr
    model: mistralai/Mistral-Small-3.2-24B-Instruct-2506
    api_key: VOTRE_CLE_API  # Obtenir sur albert.api.etalab.gouv.fr
    temperature: 0.7
    max_tokens: 4096
    timeout: 180  # AugmentÃ© pour gros modÃ¨les
    # max_parallel_tools: 1  # DÃ©tectÃ© automatiquement si besoin
```

**ModÃ¨les Albert disponibles** (voir `docs/MODEL_ALBERT.md`):
- `meta-llama/Llama-3.1-8B-Instruct` (8B, rapide)
- `mistralai/Mistral-Small-3.2-24B-Instruct-2506` (24B, puissant)
- `Qwen/Qwen2.5-Coder-32B-Instruct-AWQ` (32B, spÃ©cialisÃ© code)
- Et plus...

**DÃ©tection automatique des contraintes:**
- Le programme dÃ©tecte automatiquement les limitations des modÃ¨les (ex: un seul tool Ã  la fois)
- Les contraintes sont sauvegardÃ©es dans `~/.agentichat/model_metadata.json`
- AppliquÃ©es automatiquement au prochain lancement

## ğŸ—ï¸ Architecture

```
agentichat/
â”œâ”€â”€ src/agentichat/
â”‚   â”œâ”€â”€ cli/           # Interface CLI (app, Ã©diteur, confirmations)
â”‚   â”œâ”€â”€ backends/      # Adaptateurs LLM (Ollama, Albert, extensible)
â”‚   â”œâ”€â”€ config/        # Gestion de configuration
â”‚   â”œâ”€â”€ core/          # Boucle agentique et orchestration
â”‚   â”œâ”€â”€ tools/         # ImplÃ©mentations des outils (14 base + 4 Albert)
â”‚   â””â”€â”€ utils/         # Sandbox, logging, helpers
â””â”€â”€ docs/              # Documentation
```

## ğŸ” SÃ©curitÃ©

- **Sandbox**: Toutes les opÃ©rations fichiers sont validÃ©es contre les chemins autorisÃ©s
- **Confirmations**: Les opÃ©rations destructives (suppression, shell) nÃ©cessitent approbation
- **Transparence**: Tous les appels d'outils sont loggÃ©s et visibles

## ğŸ¯ Comparaison avec Autres Outils

| Outil | Type | Cas d'Usage |
|------|------|-------------|
| `llm` (Simon Willison) | Outil CLI de prompt | Prompts rapides, scriptable |
| `llama-agents` | Framework multi-agents | Construire systÃ¨mes agents complexes |
| `agentichat` | **CLI Agentique** | **Assistant autonome prÃªt Ã  l'emploi** |

**agentichat** comble le fossÃ© entre le prompting simple et les frameworks complexes - c'est un assistant autonome qui fonctionne immÃ©diatement.

## ğŸ§ª DÃ©veloppement

### Lancer les Tests

```bash
pip install -e ".[dev]"
pytest
```

### QualitÃ© du Code

```bash
# Linting
ruff check .
ruff format .

# VÃ©rification de types
mypy src/
```

## ğŸ› Gestion des Erreurs Communes

### Rate Limit API Albert
```
âš  Quota API dÃ©passÃ©: 128000 input tokens per minute exceeded
```
**Solutions:**
- Attendez ~60 secondes
- Utilisez `/clear` pour rÃ©duire l'historique
- Utilisez un modÃ¨le plus petit

### Contrainte Single Tool
```
âš  Contrainte dÃ©tectÃ©e: only supports single tool-calls
```
**Solution:** Automatiquement sauvegardÃ©e et appliquÃ©e au prochain lancement.

### Timeout
```
TimeoutError
```
**Solutions:**
- Augmentez `timeout: 180` dans config
- Utilisez un modÃ¨le plus rapide

## ğŸ“ Licence

MIT

## ğŸ™ Remerciements

Construit avec:
- [Ollama](https://ollama.ai/) - Runtime LLM local
- [Rich](https://github.com/Textualize/rich) - Formatage terminal
- [prompt_toolkit](https://github.com/prompt-toolkit/python-prompt-toolkit) - CLI interactive
- [Albert API](https://albert.api.etalab.gouv.fr) - API IA service public franÃ§ais

---

# English Version

**Autonomous AI assistant in your terminal** - Talk to your files, the web, and your tasks with agentic AI powered by Ollama or Albert API.

## âœ¨ Features

- ğŸ¤– **Agentic AI**: Autonomous assistant with 18 built-in tools (14 base + 4 Albert)
- ğŸ“ **File Operations**: Read, write, search, list files and directories
- ğŸŒ **Web Access**: Fetch URLs and search the web (DuckDuckGo)
- ğŸ“‹ **Task Management**: Built-in TODO list with status tracking
- ğŸ”„ **Interactive UX**: Real-time stats, confirmations, model selector
- ğŸ”’ **Secure**: Sandboxed file operations with user confirmations
- âš¡ **Fast**: Optimized for Ollama with streaming support
- ğŸ‡«ğŸ‡· **Albert API**: Support for Albert API (Etalab) with specialized tools

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- [Ollama](https://ollama.ai/) installed and running OR
- An [Albert API](https://albert.api.etalab.gouv.fr) account (French public service)

### Installation

```bash
# Install from source
git clone <repository>
cd agentichat
python -m venv .venv
source .venv/bin/activate  # or `.venv\Scripts\activate` on Windows
pip install -e .
```

### First Run

```bash
agentichat
```

On first run, the program will:
1. Detect if your configured model is invalid
2. Show an interactive model selector
3. Save your choice to configuration

## ğŸ› ï¸ Available Tools

The AI assistant has access to 18 tools organized by category:

### ğŸ“ Files (6 tools)
- `read_file` - Read file contents
- `write_file` - Create or modify files
- `list_files` - List directory contents
- `delete_file` - Delete files
- `search_text` - Search text with regex
- `glob_search` - Find files by pattern (e.g., `*.py`, `**/*.js`)

### ğŸ“‚ Directories (4 tools)
- `create_directory` - Create directories
- `delete_directory` - Remove directories
- `move_file` - Move/rename files or directories
- `copy_file` - Copy files or directories

### ğŸŒ Web (2 tools)
- `web_fetch` - Fetch content from URLs
- `web_search` - Search the web (DuckDuckGo)

### ğŸ’» System (1 tool)
- `shell_exec` - Execute shell commands

### ğŸ“‹ Productivity (1 tool)
- `todo_write` - Manage task lists with status tracking

### âš¡ Albert API only (4 additional tools)
- `albert_search` - Semantic search in document collections
- `albert_ocr` - Extract text from images/PDFs
- `albert_transcription` - Convert audio to text
- `albert_embeddings` - Create text embeddings for similarity

## ğŸ’¬ Usage

### Interactive Mode

```bash
agentichat
```

Just ask natural language questions:
```
> List all Python files in this directory
> Read the config file and explain what it does
> Search the web for "Ollama function calling"
> Create a TODO list for this project
```

The AI will automatically use the appropriate tools to complete your requests.

### Commands

#### General Commands
- `/help` - Show help
- `/quit`, `/exit`, `/q` - Quit
- `/clear` - Reset conversation
- `/config` - Show configuration
- `/config backend list` - List available backends
- `/config backend <name>` - Switch backend (ollama/albert)

#### Ollama Commands
- `/ollama list` - List available models
- `/ollama run <model>` - Switch model
- `/ollama show <model>` - Show model details
- `/ollama ps` - Show running models

#### Albert Commands
- `/albert list` - List available Albert models
- `/albert run <model>` - Switch Albert model
- `/albert show <model>` - Show model details
- `/albert usage` - Show usage statistics
- `/albert me` - Show account information

### Keyboard Shortcuts

- `Enter` - Send message
- `Alt+Enter` or `Ctrl+J` - New line
- `â†‘` / `â†“` - Navigate history (on first/last line)
- `Esc` - Clear current input
- `Ctrl+D` - Quit

## âš™ï¸ Configuration

Configuration file locations (in priority order):
1. `.agentichat/config.yaml` (workspace local)
2. `~/.agentichat/config.yaml` (global)

### Basic Configuration (Ollama)

```yaml
default_backend: ollama

backends:
  ollama:
    type: ollama
    url: http://localhost:11434
    model: qwen2.5-coder:7b
    temperature: 0.7
    max_tokens: 4096
    timeout: 300

sandbox:
  max_file_size: 1000000  # 1 MB
  blocked_paths:
    - "**/.env"
    - "**/*.key"

confirmations:
  text_operations: true
  shell_commands: true

max_iterations: 10
```

### Using Albert API (Etalab)

Albert is a French public service API providing advanced features:

```yaml
default_backend: albert

backends:
  albert:
    type: albert
    url: https://albert.api.etalab.gouv.fr
    model: mistralai/Mistral-Small-3.2-24B-Instruct-2506
    api_key: YOUR_API_KEY  # Get one at albert.api.etalab.gouv.fr
    temperature: 0.7
    max_tokens: 4096
    timeout: 180  # Increased for large models
    # max_parallel_tools: 1  # Auto-detected if needed
```

**Available Albert models** (see `docs/MODEL_ALBERT.md`):
- `meta-llama/Llama-3.1-8B-Instruct` (8B, fast)
- `mistralai/Mistral-Small-3.2-24B-Instruct-2506` (24B, powerful)
- `Qwen/Qwen2.5-Coder-32B-Instruct-AWQ` (32B, code-specialized)
- And more...

**Automatic constraint detection:**
- Program automatically detects model limitations (e.g., single tool at a time)
- Constraints are saved in `~/.agentichat/model_metadata.json`
- Automatically applied on next launch

## ğŸ—ï¸ Architecture

```
agentichat/
â”œâ”€â”€ src/agentichat/
â”‚   â”œâ”€â”€ cli/           # CLI interface (app, editor, confirmations)
â”‚   â”œâ”€â”€ backends/      # LLM adapters (Ollama, Albert, extensible)
â”‚   â”œâ”€â”€ config/        # Configuration management
â”‚   â”œâ”€â”€ core/          # Agent loop and orchestration
â”‚   â”œâ”€â”€ tools/         # Tool implementations (14 base + 4 Albert)
â”‚   â””â”€â”€ utils/         # Sandbox, logging, helpers
â””â”€â”€ docs/              # Documentation
```

## ğŸ” Security

- **Sandbox**: All file operations are validated against allowed paths
- **Confirmations**: Destructive operations (delete, shell exec) require user approval
- **Transparency**: All tool calls are logged and visible

## ğŸ¯ Comparison with Other Tools

| Tool | Type | Use Case |
|------|------|----------|
| `llm` (Simon Willison) | CLI prompt tool | Quick prompts, scriptable |
| `llama-agents` | Multi-agent framework | Build complex agent systems |
| `agentichat` | **Agentic CLI** | **Ready-to-use autonomous assistant** |

**agentichat** fills the gap between simple prompting and complex frameworks - it's an autonomous assistant that works out of the box.

## ğŸ§ª Development

### Run Tests

```bash
pip install -e ".[dev]"
pytest
```

### Code Quality

```bash
# Linting
ruff check .
ruff format .

# Type checking
mypy src/
```

## ğŸ› Common Error Handling

### Albert API Rate Limit
```
âš  Quota API dÃ©passÃ©: 128000 input tokens per minute exceeded
```
**Solutions:**
- Wait ~60 seconds
- Use `/clear` to reduce history
- Use a smaller model

### Single Tool Constraint
```
âš  Constraint detected: only supports single tool-calls
```
**Solution:** Automatically saved and applied on next launch.

### Timeout
```
TimeoutError
```
**Solutions:**
- Increase `timeout: 180` in config
- Use a faster model

## ğŸ“ License

MIT

## ğŸ™ Acknowledgments

Built with:
- [Ollama](https://ollama.ai/) - Local LLM runtime
- [Rich](https://github.com/Textualize/rich) - Terminal formatting
- [prompt_toolkit](https://github.com/prompt-toolkit/python-prompt-toolkit) - Interactive CLI
- [Albert API](https://albert.api.etalab.gouv.fr) - French public service AI API
