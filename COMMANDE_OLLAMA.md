# Commande /ollama - Dialogue direct avec Ollama

La commande `/ollama` permet de dialoguer directement avec le serveur Ollama et de gérer vos modèles sans quitter agentichat.

## Commandes disponibles

### 1. `/ollama list` - Liste tous les modèles

Affiche tous les modèles disponibles sur le serveur Ollama avec leur taille et date de modification.

```bash
> /ollama list

=== Modèles disponibles (5) ===
● qwen2.5:3b                    1.90 GB  2025-12-04T09:30:15
  llama3:8b                     4.66 GB  2025-12-03T14:22:10
  starcoder2:7b                 3.77 GB  2025-12-02T11:15:05
  mistrallite:latest            3.83 GB  2025-12-01T16:45:30
  deepseek-coder:1.3b           0.72 GB  2025-11-30T10:20:00
```

**Légende:**
- `●` (point vert) = modèle actuellement utilisé
- Les tailles sont affichées en GB
- La date de modification est au format ISO

---

### 2. `/ollama show <model>` - Informations détaillées

Affiche les informations complètes d'un modèle (Modelfile, template, paramètres).

```bash
> /ollama show qwen2.5:3b

=== Informations: qwen2.5:3b ===

Modelfile:
  # Modelfile generated by "ollama show"
  # To build a new Modelfile based on this, replace FROM with:
  # FROM qwen2.5:3b

  FROM /models/qwen2.5-3b-q4_0.gguf
  TEMPLATE """{{ .System }}
  {{ .Prompt }}"""
  PARAMETER temperature 0.7
  ...

Template: {{ .System }}\n{{ .Prompt }}...

Parameters: temperature=0.7 top_p=0.95 top_k=40...
```

**Utilité:**
- Voir la configuration d'un modèle
- Copier le Modelfile pour créer une variante
- Vérifier les paramètres (température, etc.)

---

### 3. `/ollama run <model>` - Changer de modèle

**Fonctionnalité clé**: Change de modèle à la volée sans redémarrer agentichat.

```bash
# Afficher les modèles disponibles
> /ollama list

# Changer vers un autre modèle
> /ollama run llama3:8b

✓ Modèle changé: qwen2.5:3b → llama3:8b

# Continuer la conversation avec le nouveau modèle
> Bonjour, quel modèle es-tu maintenant ?
```

**Fonctionnement:**
- Vérifie que le modèle existe avant de changer
- Met à jour le backend Ollama avec le nouveau modèle
- Toutes les requêtes suivantes utilisent le nouveau modèle
- L'historique de conversation est préservé

**Cas d'usage:**
- Tester différents modèles pour la même tâche
- Passer à un modèle plus puissant pour une tâche complexe
- Utiliser un modèle plus rapide pour des tâches simples

---

### 4. `/ollama ps` - Modèles en cours d'exécution

Liste les modèles actuellement chargés en mémoire par Ollama.

```bash
> /ollama ps

=== Modèles en cours (2) ===
  qwen2.5:3b                    1.90 GB
  llama3:8b                     4.66 GB
```

**Utilité:**
- Voir quels modèles consomment de la mémoire
- Savoir si un modèle doit être chargé (première requête plus lente)

---

### 5. `/ollama create <name> <path>` - Créer un modèle

Crée un nouveau modèle personnalisé à partir d'un Modelfile.

```bash
> /ollama create mycoder ./Modelfile.coder

Création du modèle 'mycoder'...
  pulling base model...
  creating model layer...
  writing manifest...

✓ Modèle 'mycoder' créé avec succès
```

**Exemple de Modelfile** (`Modelfile.coder`):
```
FROM qwen2.5:3b

PARAMETER temperature 0.5
PARAMETER top_p 0.9

SYSTEM """
Tu es un assistant expert en programmation Python.
Réponds de manière concise avec des exemples de code.
"""
```

**Utilité:**
- Créer des modèles spécialisés (coding, docs, etc.)
- Ajuster les paramètres par défaut
- Définir un prompt système personnalisé

---

### 6. `/ollama cp <source> <destination>` - Copier un modèle

Copie un modèle existant vers un nouveau nom.

```bash
> /ollama cp qwen2.5:3b qwen2.5:3b-backup

✓ Modèle copié: qwen2.5:3b → qwen2.5:3b-backup
```

**Utilité:**
- Créer des sauvegardes avant modification
- Dupliquer un modèle pour expérimentation
- Renommer un modèle (copie + suppression de l'ancien)

**Note:** Nécessite les permissions appropriées sur le serveur Ollama.

---

### 7. `/ollama rm <model>` - Supprimer un modèle

Supprime un modèle du serveur Ollama après confirmation.

```bash
> /ollama rm old-model

Supprimer le modèle 'old-model' ? (yes/no): yes

✓ Modèle 'old-model' supprimé
```

**Sécurité:**
- Demande toujours confirmation
- Taper "yes" ou "y" pour confirmer
- Toute autre réponse annule l'opération

**Note:** Nécessite les permissions appropriées (typiquement propriétaire du serveur).

---

## Exemples de workflow

### Workflow 1: Explorer et tester des modèles

```bash
# 1. Lister les modèles disponibles
> /ollama list

# 2. Voir les détails d'un modèle intéressant
> /ollama show llama3:8b

# 3. Changer vers ce modèle
> /ollama run llama3:8b

# 4. Tester avec une question
> Explique-moi les closures en JavaScript

# 5. Revenir au modèle précédent si besoin
> /ollama run qwen2.5:3b
```

### Workflow 2: Créer un modèle personnalisé

```bash
# 1. Créer un Modelfile
# (éditer Modelfile.assistant avec vim/nano/etc.)

# 2. Créer le modèle
> /ollama create my-assistant ./Modelfile.assistant

# 3. Vérifier qu'il apparaît
> /ollama list

# 4. L'utiliser
> /ollama run my-assistant

# 5. Tester
> Bonjour !
```

### Workflow 3: Gestion de l'espace disque

```bash
# 1. Voir quels modèles sont installés
> /ollama list

# 2. Voir les détails d'un gros modèle
> /ollama show llama3:70b

# 3. Supprimer les modèles inutilisés
> /ollama rm old-model-v1
> /ollama rm experimental-v2

# 4. Vérifier l'espace libéré
> /ollama list
```

---

## Intégration avec les autres commandes

La commande `/ollama` s'intègre parfaitement avec les autres commandes de agentichat:

```bash
# Activer le debug pour voir les requêtes Ollama
> /config debug on

# Changer de modèle
> /ollama run llama3:8b

# Voir les logs de la connexion
> /log show

# Vérifier la configuration actuelle
> /config show
```

---

## Limitations et permissions

### Opérations sans restriction
- `/ollama list` - Toujours disponible
- `/ollama show` - Toujours disponible
- `/ollama run` - Toujours disponible (si modèle existe)
- `/ollama ps` - Toujours disponible

### Opérations avec permissions
- `/ollama create` - Peut échouer selon la config du serveur
- `/ollama cp` - Nécessite droits d'écriture
- `/ollama rm` - Nécessite droits de suppression (généralement propriétaire)

### Serveur distant
Si vous vous connectez à un serveur Ollama distant, certaines opérations peuvent être restreintes ou interdites selon les permissions de l'utilisateur.

---

## Messages d'erreur courants

### "Modèle non trouvé"
```bash
> /ollama run nonexistent:model

Erreur: Modèle 'nonexistent:model' non trouvé
Modèles disponibles: qwen2.5:3b, llama3:8b, ...
```

**Solution:** Utilisez `/ollama list` pour voir les modèles disponibles.

### "Commandes Ollama disponibles uniquement avec le backend Ollama"
```bash
Erreur: Commandes Ollama disponibles uniquement avec le backend Ollama
```

**Cause:** Vous utilisez un autre backend (OpenAI, vLLM, etc.)

**Solution:** Configurez le backend Ollama dans `~/.agentichat/config.yaml`

### "Connection error"
```bash
Erreur: Connection error: Cannot connect to host localhost:11434
```

**Cause:** Le serveur Ollama n'est pas en cours d'exécution

**Solution:**
```bash
# Démarrer Ollama
$ ollama serve
```

---

## Conseils et bonnes pratiques

### 1. Vérifier avant de changer
Avant de changer de modèle avec `/ollama run`, vérifiez qu'il existe avec `/ollama list`.

### 2. Tester avec des modèles légers
Pour tester rapidement, utilisez des modèles légers (1-3B paramètres) avant de passer à des modèles plus gros.

### 3. Surveiller la mémoire
Utilisez `/ollama ps` pour voir combien de modèles sont chargés simultanément.

### 4. Sauvegarder avant de modifier
Avant de supprimer ou modifier un modèle, faites une copie avec `/ollama cp`.

### 5. Utiliser les logs
Activez le debug (`/config debug on`) pour voir les détails des interactions avec Ollama.

---

## Architecture technique

```
ChatApp
├── OllamaManager (nouveau)
│   ├── list_models() - GET /api/tags
│   ├── show_model() - POST /api/show
│   ├── list_running() - GET /api/ps
│   ├── create_model() - POST /api/create (streaming)
│   ├── copy_model() - POST /api/copy
│   └── delete_model() - DELETE /api/delete
│
├── OllamaBackend
│   └── set_model() - Change le modèle à la volée
│
└── _handle_ollama_command() (nouveau)
    ├── list
    ├── show
    ├── run - change backend.model
    ├── ps
    ├── create
    ├── cp
    └── rm
```

---

## Aide rapide

```bash
/ollama list                    # Liste les modèles
/ollama show <model>            # Info détaillées
/ollama run <model>             # Change de modèle
/ollama ps                      # Modèles en cours
/ollama create <name> <path>    # Crée un modèle
/ollama cp <src> <dst>          # Copie un modèle
/ollama rm <model>              # Supprime un modèle
```

Pour plus d'informations: `/help`
